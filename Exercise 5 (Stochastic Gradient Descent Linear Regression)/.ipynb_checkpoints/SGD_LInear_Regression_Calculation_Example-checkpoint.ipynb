{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c83dbb",
   "metadata": {},
   "source": [
    "# Calculation example for Stochastic Gradient Descent and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can do the exercise on paper! Read through the exercise carefully. The calculations start at section 2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbfbcea",
   "metadata": {},
   "source": [
    "## 1) Prepare a dataset for the linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1e419",
   "metadata": {},
   "source": [
    "### 1.1) Example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51e7f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset (x values)\n",
    "X = [\n",
    "    [8, 2],\n",
    "    [2, 8],\n",
    "    [1, 4],\n",
    "    [3, 6],\n",
    "    [9, 4],\n",
    "    [6, 5]\n",
    "]\n",
    "\n",
    "# Dependent variable on X (output of the model)\n",
    "# first row in X corresponds to first row in y and so forth\n",
    "y = [\n",
    "    4,\n",
    "    -14,\n",
    "    -7,\n",
    "    -9,\n",
    "    1,\n",
    "    -4\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6824d",
   "metadata": {},
   "source": [
    "### 1.2) Depending on the dataset we think that a Linear Regression model fits the best to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34e3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The formular for two independent input variables for linear regresion is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28e65e",
   "metadata": {},
   "source": [
    "$y_{hat}= w_1x_1 + w_2x_2 + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4527b",
   "metadata": {},
   "source": [
    "### 1.3) We need a function to evaluate to model outcome - Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586cc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example we define our loss function to be the 'Mean Squared Error' function.\n",
    "# Keep in mind that we are not bound to this method and that we can choose 'whatever' function we want to use.\n",
    "# The function should be a representative function to estimate the models performance (How good is my model?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e49c7",
   "metadata": {},
   "source": [
    "$$L = MSE = \\frac{1}{n}\\sum_{i=1}^n (y_{i_{hat}}-y_{i})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general for classical approaches: The lower the loss the better the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd4d9cc",
   "metadata": {},
   "source": [
    "### 1.4) How can we minimize the loss of our model? - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbf2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is were Stochastic Gradient Descent comes into play!\n",
    "# We need to calculate the gradients of our model parameters (w_1, w_2, b) and update their values!\n",
    "\n",
    "# Calculation follows!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b445a",
   "metadata": {},
   "source": [
    "## 2) How to use all the information from above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3791fdb2",
   "metadata": {},
   "source": [
    "### 2.1) Initialize random values for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19475f3",
   "metadata": {},
   "source": [
    "$w_1, w_2, b$\n",
    "\n",
    "e. g.\n",
    "\n",
    "$w_1 = -0.5$, $w_2 = 0.02$, $b = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a9b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter value initialization is only done once (at the beginning)\n",
    "# We need these random values because we don't know anything about them at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63fa7c",
   "metadata": {},
   "source": [
    "### 2.2) Use the parameter values and one data row of the dataset and calculate the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for example the first row of X as x_1 and x_2 values and\n",
    "# calculate the output with the initially set parameter values w_1, w_2, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "616e0bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.96"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO !\n",
    "x_1 = X[0][0]\n",
    "x_2 = X[0][1]\n",
    "\n",
    "w_1 = -0.5\n",
    "w_2 = 0.02\n",
    "b = 0\n",
    "\n",
    "y_0_hat = w_1 * (x_1) + w_2 * (x_2) + b\n",
    "\n",
    "y_0_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720932d",
   "metadata": {},
   "source": [
    "### 2.3) Calculate the loss of the model - How good is our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to find out how good our model is regarding our defined loss function\n",
    "# Therefore, calculate to loss of our model based on the defined loss function above\n",
    "# Use the correct y from the data (e. g. if you use the first row X[0] then you have to use y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b203e63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.3616"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO !\n",
    "\n",
    "(y_0_hat - y[0]) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b048e0b",
   "metadata": {},
   "source": [
    "### 2.4) Calculate the gradients of the learning parameters (w_1, w_2 and b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gradients can be calculated using the partial derivatives with respect to the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d11e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with the derivation of our loss function because this is our evaluation function.\n",
    "# The loss function gives us information about how good our model performs\n",
    "# We want to update our parameters based on our quality measurement function (loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0b87fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.92"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partially derive the loss function (you can write the end result in code)\n",
    "\n",
    "# TODO !\n",
    "m_L_wrt_yhat = 2 * (y_0_hat - y[0])\n",
    "\n",
    "m_L_wrt_yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86f34d",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial y_{hat}} = 2(y_{hat}-y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ac392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parially derive the model function with respect to every parameter..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865c7ea",
   "metadata": {},
   "source": [
    "$y_{hat}= w_1x_1 + w_2x_2 + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a73753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example for w_1... where x_1 from one data row the first entry (column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83093d8f",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial y_{hat}}{\\partial w_1} = x_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this for w_1, w_2 and b with for example the first data row X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "532f89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO !\n",
    "m_yhat_wrt_w1 = x_1\n",
    "m_yhat_wrt_w2 = x_2\n",
    "m_yhat_wrt_b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c133fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to combine the loss function derivation and all the parameter derivations to calculate the final gradient\n",
    "# this can be done by the chain rule!\n",
    "# that is backtracing the output and the finding the impact for every single parameter\n",
    "# the chain rule is just combining the partial derivatives from the end of the model (loss fn) to the parameter we search for\n",
    "# the chain rule for the paramter w_1 is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171f5ef",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial w_{1}} = \\frac{\\partial L}{\\partial y_{hat}} * \\frac{\\partial y_{hat}}{\\partial w_1}$$\n",
    "$$\\frac{\\partial L}{\\partial w_{1}} = 2(y_{hat}-y) * x_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the gradient for all parameters w_1, w_2 and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6193211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO !\n",
    "\n",
    "m_L_wrt_w2 = m_L_wrt_yhat * m_yhat_wrt_w2\n",
    "m_L_wrt_b = m_L_wrt_yhat * m_yhat_wrt_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48dd68",
   "metadata": {},
   "source": [
    "### 2.5) Apply the parameter update rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41dabdd",
   "metadata": {},
   "source": [
    "$$\\theta := \\theta - \\eta\\Delta_{\\theta}L(\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For w_1 this looks as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94400c",
   "metadata": {},
   "source": [
    "$$w_1 := w_1 - \\eta \\space(\\frac{\\partial L}{\\partial y_{hat}} * \\frac{\\partial y_{hat}}{\\partial w_1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets set the learning rate eta to 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ca773",
   "metadata": {},
   "source": [
    "$$\\eta = 0.05$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25818058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the new value for all parameters w_1, w_2, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "968eeda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.612, 0.796)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO !\n",
    "\n",
    "eta = 0.05\n",
    "\n",
    "ùúÉ_for_w2 = w_2 - n * (m_L_wrt_w2)\n",
    "ùúÉ_for_b = b - n * (m_L_wrt_b)\n",
    "\n",
    "ùúÉ_for_w2, ùúÉ_for_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4411c",
   "metadata": {},
   "source": [
    "## 3) Iterate this procedure with every data row from X and y to update your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3638616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After row 1: w_1=516.0675768844525, w_2=-429.9580182616165, b=54.89301461607278, loss=11049673.10613038\n",
      "After row 2: w_1=516.1611223235608, w_2=-429.5838365051832, b=54.93978733562694, loss=5469218.236230039\n",
      "After row 3: w_1=516.183927012288, w_2=-429.4926177502743, b=54.96259202435417, loss=1300134.5698647308\n",
      "After row 4: w_1=516.2417934922944, w_2=-429.37688479026144, b=54.98188085102298, loss=930147.0856483497\n",
      "After row 5: w_1=515.7049164053327, w_2=-429.6154968289111, b=54.92222784136057, loss=8896203.904459707\n",
      "After row 6: w_1=515.5843074962772, w_2=-429.71600425312397, b=54.90212635651799, loss=1010174.2321907841\n"
     ]
    }
   ],
   "source": [
    "# One iteration is using all data given once\n",
    "# Epochs can be defined to iterate over all data rows multiple times\n",
    "\n",
    "sum_of_squared_errors = 0\n",
    "eta = 0.00001\n",
    "\n",
    "for row in range (len(X)):\n",
    "    x_1 = X[row][0]\n",
    "    x_2 = X[row][1]\n",
    "    y_i = y[row]\n",
    "    y_i_hat = w_1 * (x_1) + w_2 * (x_2) + b\n",
    "    \n",
    "    squared_loss = (y_i_hat - y_i) ** 2\n",
    "    \n",
    "    sum_of_squared_errors += squared_loss\n",
    "    \n",
    "    m_L_wrt_yhat = 2 * (y_i_hat - y_i)\n",
    "    \n",
    "    m_yhat_wrt_w1 = x_1\n",
    "    m_yhat_wrt_w2 = x_2\n",
    "    m_yhat_wrt_b = 1\n",
    "    \n",
    "    m_L_wrt_w1 = m_L_wrt_yhat * m_yhat_wrt_w1\n",
    "    m_L_wrt_w2 = m_L_wrt_yhat * m_yhat_wrt_w2\n",
    "    m_L_wrt_b = m_L_wrt_yhat * m_yhat_wrt_b\n",
    "    \n",
    "    w_1 = w_1 - eta * m_L_wrt_w1\n",
    "    w_2 = w_2 - eta * m_L_wrt_w2\n",
    "    b = b - eta * m_L_wrt_b\n",
    "    \n",
    "    print(f'After row {row + 1}: w_1={w_1}, w_2={w_2}, b={b}, loss={squared_loss}')\n",
    "    \n",
    "mean_sum_of_squared_errors = sum_of_squared_errors / (len(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
