{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865d7567",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f1031",
   "metadata": {},
   "source": [
    "Implement a logistic (binary) regression model and use your stochastic gradient descent approach from the last practicals to optimize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910c0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can import your code from a different notebook like follows (change it to your path)\n",
    "\n",
    "# %run ..\\5_SGD_Linear_Regression\\SGD_Solution.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc5873",
   "metadata": {},
   "source": [
    "## Data for the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d124ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743256fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resulting data for training and test are in (X_train, y_train) and (X_test, y_test), respectively.\n",
    "\n",
    "# Lets assume we have some data points that define the data as 'fraud' or 'no fraud', e. g. in bank account scenarios.\n",
    "# We therefore have three values given ('number of withdrawals per week', 'avg_withdrawal_amount', 'number_of_different_addressees').\n",
    "\n",
    "data_amount = 15\n",
    "frauds_amount = data_amount // 2\n",
    "no_frauds_amount = data_amount - frauds_amount\n",
    "\n",
    "### Generate (fake) 'fraud' data\n",
    "# number of withdrawals per week (fraud) - between 0 and 0.5\n",
    "X_1_f = np.random.rand(frauds_amount) / 2\n",
    "# average withdrawal amount 'fraud' - between 0.5 and 1\n",
    "X_2_f = (np.random.rand(frauds_amount) + 1) / 2\n",
    "# number of different addressees 'fraud' - between 0 and 0.5\n",
    "X_3_f = np.random.rand(frauds_amount) / 2\n",
    "\n",
    "X_f = np.stack([X_1_f, X_2_f, X_3_f], axis=1)\n",
    "\n",
    "# Labels of 'fraud' (1)\n",
    "y_f = np.ones(frauds_amount)\n",
    "\n",
    "### Generate (fake) 'no fraud' data - between 0.5 and 1\n",
    "X_1_nf = (np.random.rand(no_frauds_amount) + 1) / 2\n",
    "# average withdrawal amount 'no fraud' - between 0 and 0.5\n",
    "X_2_nf = np.random.rand(no_frauds_amount) / 2\n",
    "# number of different addressees 'no fraud' - between 0.5 and 1\n",
    "X_3_nf = (np.random.rand(no_frauds_amount) + 1) / 2\n",
    "\n",
    "X_nf = np.stack([X_1_nf, X_2_nf, X_3_nf], axis=1)\n",
    "\n",
    "# Labels of 'no fraud' (0)\n",
    "y_nf = np.zeros(no_frauds_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d8549",
   "metadata": {},
   "source": [
    "## Shuffle fraud and no fraud data to create a mixed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753d811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them (concatenate)\n",
    "X = np.concatenate((X_f, X_nf))\n",
    "y = np.concatenate((y_f, y_nf))\n",
    "\n",
    "# now randomly shuffle them\n",
    "shuffled_indices = np.random.choice(y.shape[0], size=y.shape[0], replace=False)\n",
    "X = X[shuffled_indices]\n",
    "y = y[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d5ca7",
   "metadata": {},
   "source": [
    "## Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4d5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(data_amount * 0.75)\n",
    "\n",
    "# We train with the following data\n",
    "X_train = X[:train_len]\n",
    "y_train = y[:train_len]\n",
    "\n",
    "# We test / evaluate with the following data\n",
    "X_test = X[train_len:]\n",
    "y_test = y[train_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2880fc3",
   "metadata": {},
   "source": [
    "## Initialize the weights of your logistic regression model (see SGD exercise on how to do this with numpy - dont forget to initialize the bias nodes as well!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155071b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "weights = np.random.randn(X_train.shape[1])\n",
    "bias = np.random.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9268",
   "metadata": {},
   "source": [
    "## Define the loss function (derivative) for your logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe131ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def compute_gradient(X, y_true, y_pred):\n",
    "    error = y_pred - y_true\n",
    "    dW = np.dot(X.T, error) / len(y_true)\n",
    "    db = np.mean(error)\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e102bd",
   "metadata": {},
   "source": [
    "## Define the activation function for your logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a13e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint:  How do you scale your output for logistic regression? What is the range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c133b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use your Stochastic Gradient Descent approach from the previous exercise and optimize your weights.\n",
    "# If your SGD implementation cannot do this, adjust the function implementation until it is able to do it :)\n",
    "\n",
    "learning_rate = 0.005\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8927dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "def stochastic_gradient_descent(X, y, weights, bias, learning_rate, iterations):\n",
    "    for i in range(iterations):\n",
    "        for j in range(len(y)):\n",
    "            x_i = X[j]\n",
    "            y_i = y[j]\n",
    "            y_pred = sigmoid(np.dot(x_i, weights) + bias)\n",
    "            error = y_pred - y_i\n",
    "            weights -= learning_rate * error * x_i\n",
    "            bias -= learning_rate * error\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            y_pred_all = sigmoid(np.dot(X, weights) + bias)\n",
    "            loss = compute_loss(y, y_pred_all)\n",
    "            print(f'Iteration {i}: Loss = {loss}')\n",
    "    \n",
    "    return weights, bias\n",
    "\n",
    "# Training the model\n",
    "learning_rate = 0.005\n",
    "iterations = 1000\n",
    "\n",
    "weights, bias = stochastic_gradient_descent(X_train, y_train, weights, bias, learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f144a8",
   "metadata": {},
   "source": [
    "## Predict the values for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb00461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f700e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights, bias):\n",
    "    return sigmoid(np.dot(X, weights) + bias)\n",
    "\n",
    "y_pred_test = predict(X_test, weights, bias)\n",
    "y_pred_test_labels = (y_pred_test >= 0.5).astype(int)\n",
    "\n",
    "accuracy = np.mean(y_pred_test_labels == y_test)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
